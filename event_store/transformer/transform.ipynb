{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/06/02 16:39:11 WARN Utils: Your hostname, Aarons-MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 192.168.0.111 instead (on interface en0)\n",
      "25/06/02 16:39:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/02 16:39:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Sales Analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of the DataFrame:\n",
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Product Category: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- Price per Unit: integer (nullable = true)\n",
      " |-- Total Amount: integer (nullable = true)\n",
      "\n",
      "Sample data:\n",
      "+---+----------+------+---+----------------+--------+--------------+------------+\n",
      "|_c0|      Date|Gender|Age|Product Category|Quantity|Price per Unit|Total Amount|\n",
      "+---+----------+------+---+----------------+--------+--------------+------------+\n",
      "|  0|2023-11-24|  Male| 34|          Beauty|       3|            50|         150|\n",
      "|  1|2023-02-27|Female| 26|        Clothing|       2|           500|        1000|\n",
      "|  2|2023-01-13|  Male| 50|     Electronics|       1|            30|          30|\n",
      "|  3|2023-05-21|  Male| 37|        Clothing|       1|           500|         500|\n",
      "|  4|2023-05-06|  Male| 30|          Beauty|       2|            50|         100|\n",
      "|  5|2023-04-25|Female| 45|          Beauty|       1|            30|          30|\n",
      "|  6|2023-03-13|  Male| 46|        Clothing|       2|            25|          50|\n",
      "|  7|2023-02-22|  Male| 30|     Electronics|       4|            25|         100|\n",
      "|  8|2023-12-13|  Male| 63|     Electronics|       2|           300|         600|\n",
      "|  9|2023-10-07|Female| 52|        Clothing|       4|            50|         200|\n",
      "| 10|2023-02-14|  Male| 23|        Clothing|       2|            50|         100|\n",
      "| 11|2023-10-30|  Male| 35|          Beauty|       3|            25|          75|\n",
      "| 12|2023-08-05|  Male| 22|     Electronics|       3|           500|        1500|\n",
      "| 13|2023-01-17|  Male| 64|        Clothing|       4|            30|         120|\n",
      "| 14|2023-01-16|Female| 42|     Electronics|       4|           500|        2000|\n",
      "| 15|2023-02-17|  Male| 19|        Clothing|       3|           500|        1500|\n",
      "| 16|2023-04-22|Female| 27|        Clothing|       4|            25|         100|\n",
      "| 17|2023-04-30|Female| 47|     Electronics|       2|            25|          50|\n",
      "| 18|2023-09-16|Female| 62|        Clothing|       2|            25|          50|\n",
      "| 19|2023-11-05|  Male| 22|        Clothing|       3|           300|         900|\n",
      "+---+----------+------+---+----------------+--------+--------------+------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/02 16:40:56 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Date, Gender, Age, Product Category, Quantity, Price per Unit, Total Amount\n",
      " Schema: _c0, Date, Gender, Age, Product Category, Quantity, Price per Unit, Total Amount\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/aaronginder/Git/event-store/data/Sales%20Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the CSV file\n",
    "df = spark.read.csv('../../data/Sales Dataset.csv', header=True, inferSchema=True)\n",
    "\n",
    "print(\"Schema of the DataFrame:\")\n",
    "df.printSchema()\n",
    "print(\"Sample data:\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "# Drop the first index column\n",
    "df = df.drop('_c0')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+----------------+--------+--------------+------------+\n",
      "|      Date|Gender|Age|Product Category|Quantity|Price per Unit|Total Amount|\n",
      "+----------+------+---+----------------+--------+--------------+------------+\n",
      "|2023-11-24|  Male| 34|          Beauty|       3|            50|         150|\n",
      "|2023-02-27|Female| 26|        Clothing|       2|           500|        1000|\n",
      "|2023-01-13|  Male| 50|     Electronics|       1|            30|          30|\n",
      "|2023-05-21|  Male| 37|        Clothing|       1|           500|         500|\n",
      "|2023-05-06|  Male| 30|          Beauty|       2|            50|         100|\n",
      "|2023-04-25|Female| 45|          Beauty|       1|            30|          30|\n",
      "|2023-03-13|  Male| 46|        Clothing|       2|            25|          50|\n",
      "|2023-02-22|  Male| 30|     Electronics|       4|            25|         100|\n",
      "|2023-12-13|  Male| 63|     Electronics|       2|           300|         600|\n",
      "|2023-10-07|Female| 52|        Clothing|       4|            50|         200|\n",
      "|2023-02-14|  Male| 23|        Clothing|       2|            50|         100|\n",
      "|2023-10-30|  Male| 35|          Beauty|       3|            25|          75|\n",
      "|2023-08-05|  Male| 22|     Electronics|       3|           500|        1500|\n",
      "|2023-01-17|  Male| 64|        Clothing|       4|            30|         120|\n",
      "|2023-01-16|Female| 42|     Electronics|       4|           500|        2000|\n",
      "|2023-02-17|  Male| 19|        Clothing|       3|           500|        1500|\n",
      "|2023-04-22|Female| 27|        Clothing|       4|            25|         100|\n",
      "|2023-04-30|Female| 47|     Electronics|       2|            25|          50|\n",
      "|2023-09-16|Female| 62|        Clothing|       2|            25|          50|\n",
      "|2023-11-05|  Male| 22|        Clothing|       3|           300|         900|\n",
      "+----------+------+---+----------------+--------+--------------+------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/02 16:42:36 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+----------------+------------------+------------------+-----------------+\n",
      "|summary|Gender|               Age|Product Category|          Quantity|    Price per Unit|     Total Amount|\n",
      "+-------+------+------------------+----------------+------------------+------------------+-----------------+\n",
      "|  count|  1000|              1000|            1000|              1000|              1000|             1000|\n",
      "|   mean|  NULL|            41.392|            NULL|             2.514|            179.89|            456.0|\n",
      "| stddev|  NULL|13.681429659122518|            NULL|1.1327343409145354|189.68135627129234|559.9976315551235|\n",
      "|    min|Female|                18|          Beauty|                 1|                25|               25|\n",
      "|    max|  Male|                64|     Electronics|                 4|               500|             2000|\n",
      "+-------+------+------------------+----------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, date_format\n",
    "\n",
    "df = df.withColumn(\"year\", date_format(col(\"Date\"), \"yyyy\")) \\\n",
    "    .withColumn(\"month\", date_format(col(\"Date\"), \"MM\")) \\\n",
    "    .withColumn(\"day\", date_format(col(\"Date\"), \"dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 61] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBrokenPipeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/event-store/.venv/lib/python3.12/site-packages/py4j/clientserver.py:527\u001b[39m, in \u001b[36mClientServerConnection.send_command\u001b[39m\u001b[34m(self, command)\u001b[39m\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43msendall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mBrokenPipeError\u001b[39m: [Errno 32] Broken pipe",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mPy4JNetworkError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/event-store/.venv/lib/python3.12/site-packages/py4j/java_gateway.py:1038\u001b[39m, in \u001b[36mGatewayClient.send_command\u001b[39m\u001b[34m(self, command, retry, binary)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/event-store/.venv/lib/python3.12/site-packages/py4j/clientserver.py:530\u001b[39m, in \u001b[36mClientServerConnection.send_command\u001b[39m\u001b[34m(self, command)\u001b[39m\n\u001b[32m    529\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mError while sending or receiving.\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(\n\u001b[32m    531\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError while sending\u001b[39m\u001b[33m\"\u001b[39m, e, proto.ERROR_ON_SEND)\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mPy4JNetworkError\u001b[39m: Error while sending",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m.mode(\u001b[33m\"\u001b[39m\u001b[33moverwrite\u001b[39m\u001b[33m\"\u001b[39m).partitionBy(\u001b[33m\"\u001b[39m\u001b[33myear\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmonth\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mday\u001b[39m\u001b[33m\"\u001b[39m)\\\n\u001b[32m      2\u001b[39m     .parquet(\u001b[33m\"\u001b[39m\u001b[33m../data/\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/event-store/.venv/lib/python3.12/site-packages/pyspark/sql/classic/dataframe.py:195\u001b[39m, in \u001b[36mDataFrame.write\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrameWriter:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/event-store/.venv/lib/python3.12/site-packages/pyspark/sql/readwriter.py:1199\u001b[39m, in \u001b[36mDataFrameWriter.__init__\u001b[39m\u001b[34m(self, df)\u001b[39m\n\u001b[32m   1197\u001b[39m \u001b[38;5;28mself\u001b[39m._df = df\n\u001b[32m   1198\u001b[39m \u001b[38;5;28mself\u001b[39m._spark = df.sparkSession\n\u001b[32m-> \u001b[39m\u001b[32m1199\u001b[39m \u001b[38;5;28mself\u001b[39m._jwrite = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/event-store/.venv/lib/python3.12/site-packages/py4j/java_gateway.py:1361\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1354\u001b[39m args_command, temp_args = \u001b[38;5;28mself\u001b[39m._build_args(*args)\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m-> \u001b[39m\u001b[32m1361\u001b[39m answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m return_value = get_return_value(\n\u001b[32m   1363\u001b[39m     answer, \u001b[38;5;28mself\u001b[39m.gateway_client, \u001b[38;5;28mself\u001b[39m.target_id, \u001b[38;5;28mself\u001b[39m.name)\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/event-store/.venv/lib/python3.12/site-packages/py4j/java_gateway.py:1057\u001b[39m, in \u001b[36mGatewayClient.send_command\u001b[39m\u001b[34m(self, command, retry, binary)\u001b[39m\n\u001b[32m   1055\u001b[39m         retry = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1056\u001b[39m     logging.info(\u001b[33m\"\u001b[39m\u001b[33mException while sending command.\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1059\u001b[39m     logging.exception(\n\u001b[32m   1060\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mException while sending command.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/event-store/.venv/lib/python3.12/site-packages/py4j/java_gateway.py:1036\u001b[39m, in \u001b[36mGatewayClient.send_command\u001b[39m\u001b[34m(self, command, retry, binary)\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry=\u001b[38;5;28;01mTrue\u001b[39;00m, binary=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1016\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[32m   1017\u001b[39m \u001b[33;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[32m   1018\u001b[39m \u001b[33;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1034\u001b[39m \u001b[33;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m     connection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1038\u001b[39m         response = connection.send_command(command)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/event-store/.venv/lib/python3.12/site-packages/py4j/clientserver.py:284\u001b[39m, in \u001b[36mJavaClient._get_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection.socket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     connection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/event-store/.venv/lib/python3.12/site-packages/py4j/clientserver.py:291\u001b[39m, in \u001b[36mJavaClient._create_new_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    288\u001b[39m     connection = ClientServerConnection(\n\u001b[32m    289\u001b[39m         \u001b[38;5;28mself\u001b[39m.java_parameters, \u001b[38;5;28mself\u001b[39m.python_parameters,\n\u001b[32m    290\u001b[39m         \u001b[38;5;28mself\u001b[39m.gateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_thread_connection(connection)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/event-store/.venv/lib/python3.12/site-packages/py4j/clientserver.py:438\u001b[39m, in \u001b[36mClientServerConnection.connect_to_java_server\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ssl_context:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28mself\u001b[39m.socket = \u001b[38;5;28mself\u001b[39m.ssl_context.wrap_socket(\n\u001b[32m    437\u001b[39m         \u001b[38;5;28mself\u001b[39m.socket, server_hostname=\u001b[38;5;28mself\u001b[39m.java_address)\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[38;5;28mself\u001b[39m.stream = \u001b[38;5;28mself\u001b[39m.socket.makefile(\u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    440\u001b[39m \u001b[38;5;28mself\u001b[39m.is_connected = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [Errno 61] Connection refused"
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").partitionBy(\"year\", \"month\", \"day\")\\\n",
    "    .parquet(\"../data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
